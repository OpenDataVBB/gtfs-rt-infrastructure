---
- name: configure GTFS-RT converters
  hosts: gtfs_rt_converter
  become: true
  roles:
    - name: deploy NATS message queue
      role: nats
      vars:
        nats_server_name: '{{ inventory_hostname }}'
        nats_jetstream_enabled: true
        # todo: make configurable
        nats_jetstream_max_mem: 2G
        # for some reason, `max_file` needs much more than the sum of the streams' `max_bytes` ðŸ¤”ðŸ¤”
        # related: https://github.com/nats-io/nats-server/issues/4281#issuecomment-2586742483
        nats_jetstream_max_file: '{{ (nats_ref_aus_sollfahrt_stream_max_size_gb + nats_aus_istfahrt_stream_max_size_gb + nats_gtfs_rt_stream_max_size_gb) * 1.5 | round | int }}G'
        # see https://github.com/nats-io/nats.docs/blob/66c6bcc/running-a-nats-service/nats_admin/monitoring/readme.md
        # see https://github.com/nats-io/nats.docs/blob/66c6bcc/running-a-nats-service/nats_admin/monitoring/monitoring_jetstream.md
        nats_exporter_export_gatewayz: false
        nats_exporter_export_accountsz: false
        nats_exporter_export_accstatsz: false
        nats_exporter_export_leafz: false
        nats_exporter_export_routez: false
        nats_exporter_export_subz: false
        nats_exporter_export_jsz:
          # JetStream stream stats (e.g. first/last message sequence)
          - streams

    - name: install Node.js from NodeSource's repo
      role: geerlingguy.nodejs
      vars:
        nodejs_version: '22.x'

    - name: install PostgreSQL
      # role: geerlingguy.postgresql
      role: ansible-role-postgresql

    - name: install Prometheus
      role: prometheus.prometheus.prometheus
      vars:
        prometheus_web_listen_address: '{{ prometheus_listen_address }}' # only listen locally
        prometheus_storage_retention: '{{ prometheus_data_retention }}'
        prometheus_storage_retention_size: '{{ prometheus_data_retention_size }}'
        prometheus_global:
          scrape_interval: 15s
        prometheus_scrape_configs:
          - job_name: gtfs-rt-feed
            scrape_interval: 5s
            static_configs:
              - targets: ['localhost:{{ gtfs_rt_feed_metrics_server_port }}']
          - job_name: nats-consuming-gtfs-rt-server
            scrape_interval: 5s
            static_configs:
              - targets: ['{{ gtfs_rt_server_address }}:{{ nats_consuming_gtfs_rt_server_metrics_server_port }}']
          - job_name: vdv-453-nats-adapter
            scrape_interval: 5s
            static_configs:
              - targets: ['{{ vdv_453_nats_adapter_address }}:{{ vdv_453_nats_adapter_metrics_server_port }}']
          - job_name: caddy
            static_configs:
              # https://caddyserver.com/docs/metrics
              - targets:
                - '{{ gtfs_rt_server_address }}:{{ gtfs_rt_server_caddy_metrics_server_port }}'
          - job_name: prometheus-nats-exporter
            static_configs:
              - targets: ['localhost:7777']
          - job_name: prometheus-postgres-exporter
            static_configs:
              - targets: ['localhost:9187']
          - job_name: prometheus-redis-exporter
            static_configs:
              - targets: ['localhost:9121']
          - job_name: prometheus-node-exporter
            static_configs:
              - targets:
                  - '{{ vdv_453_nats_adapter_address }}:{{ prometheus_node_exporter_port }}'
                  - '{{ gtfs_rt_converter_address }}:{{ prometheus_node_exporter_port }}'
                  - '{{ gtfs_rt_server_address }}:{{ prometheus_node_exporter_port }}'
          - job_name: prometheus-systemd-exporter
            static_configs:
              - targets:
                  - '{{ vdv_453_nats_adapter_address }}:{{ prometheus_systemd_exporter_port }}'
                  - '{{ gtfs_rt_converter_address }}:{{ prometheus_systemd_exporter_port }}'
                  - '{{ gtfs_rt_server_address }}:{{ prometheus_systemd_exporter_port }}'
          - job_name: prometheus-blackbox-exporter
            scrape_interval: 10s
            # see also https://github.com/prometheus/blackbox_exporter/blob/v0.25.0/README.md#prometheus-configuration
            metrics_path: /probe
            params:
              module: ['ping_ipv4_5s']
            relabel_configs:
              - source_labels: [__address__]
                target_label: __param_target
              - source_labels: [__param_target]
                target_label: instance
              - source_labels: [__param_module]
                target_label: module
              - target_label: __address__
                # the blackbox exporter's real hostname:port
                # Note: We ping *from* the `vdv_453_nats_adapter_address` machine.
                replacement: '{{ vdv_453_nats_adapter_address }}:{{ prometheus_blackbox_exporter_port }}'
            static_configs:
              - targets:
                - '{{ vdv_453_api_host }}'
          - job_name: prometheus
            static_configs:
              - targets: ['{{ prometheus_listen_address }}']
    - name: install Prometheus PostgreSQL exporter
      role: prometheus.prometheus.postgres_exporter
      vars:
        postgres_exporter_name: 'postgresql://postgres:{{ postgresql_postgres_password }}@localhost/postgres?host=/var/run/postgresql'
        # Note: Some config values are modified via a systemd config override, see tasks below.
        postgres_exporter_disabled_collectors:
          - locks
          - replication
          - replication_slot
          - stat_bgwriter
          # The `stat_database` collector (enabled by default) exposes the database name as a label. Because postgis-gtfs-importer creates a new database on each import (gtfs_$timestamp_$hash), this creates a large number of time series.
          # > CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values.
          # â€“ https://prometheus.io/docs/practices/naming/
          # todo: investigate if this is a problem!
          # - stat_database
          - stat_user_tables
          - statio_user_tables
          - wal
        # default is `0.0.0.0:9187`
        postgres_exporter_web_listen_address: 'localhost:9187'
    - name: install Prometheus Redis exporter
      role: prometheus.prometheus.redis_exporter
      vars:
        # todo: adapt gtfs-rt-feed's keys naming, then use `redis_exporter_check_key_groups` to get insights into key usage
        # todo: adapt gtfs-rt-feed's keys naming to something more meaningful & self-explanatory!
        redis_exporter_count_keys:
          - '{{ gtfs_rt_feed_redis_db }}=*'
        redis_exporter_incl_system_metrics: true
        redis_exporter_redis_only_metrics: true
        # default is `0.0.0.0:9121`
        redis_exporter_web_listen_address: 'localhost:9121'

    # todo: as of 2025-07-18 it doesn't work with Ubuntu 25
    - name: install & configure Grafana
      role: grafana.grafana.grafana
      vars:
        grafana_ini:
          server:
            http_addr: '{{ grafana_http_addr }}'
            http_port: '{{ grafana_http_port }}'
            root_url: '{{ grafana_public_endpoints[0] }}'
          security:
            admin_user: admin
            admin_password: '{{ grafana_admin_password }}'
        grafana_datasources:
          - uid: 'de29irtzi5gcga' # must match the `uid` in the dashboard files!
            name: 'prometheus localhost'
            type: prometheus
            access: proxy
            url: 'http://{{ prometheus_listen_address }}'
        grafana_dashboards_dir: ../lib/grafana/dashboards
        grafana_alert_resources: "{{ lookup('template', '../lib/grafana/alerting.yaml.j2') | from_yaml }}"

  tasks:
    - name: set password of "postgres" user
      ansible.builtin.shell: |
        sudo -u postgres psql -c "ALTER USER postgres PASSWORD '{{ postgresql_postgres_password }}'"
    - name: install PostGIS
      package:
        name:
          - postgis
    - name: tweak PostgreSQL settings for matching performance
      ansible.builtin.template:
        src: '../templates/gtfs-rt.postgresql.conf'
        dest: /etc/postgresql/{{ postgresql_major_version }}/main/conf.d/gtfs-rt.conf
        owner: postgres
        group: postgres
    - name: reload PostgreSQL
      ansible.builtin.systemd_service:
        state: reloaded
        name: postgresql

    - name: create directory /etc/systemd/system/postgres_exporter.service.d
      ansible.builtin.file:
        path: /etc/systemd/system/postgres_exporter.service.d
        state: directory
    - name: "Prometheus PostgreSQL exporter: put systemd config override to prevent scraping pg_settings"
      ansible.builtin.copy:
        src: ../lib/prometheus/postgres-exporter-disable-pg-settings.conf
        dest: /etc/systemd/system/postgres_exporter.service.d/disable-pg-settings.conf
    - name: systemd daemon-reload & restart systemd postgres_exporter.service
      ansible.builtin.systemd_service:
        daemon_reload: true
        state: restarted
        name: postgres_exporter

    # todo: use geerlingguy.redis once it supports Redis v8 â€“ currently it only uses the stock Ubuntu sources, which have v7
    # https://github.com/geerlingguy/ansible-role-redis
    - name: install Redis v8
      block:
      - name: install Redis PPA signing key
        ansible.builtin.shell: |
          curl -fsSL https://packages.redis.io/gpg | gpg --dearmor -o /etc/apt/keyrings/redis-archive-keyring.gpg
      - name: add Redis repository to APT sources
        ansible.builtin.apt_repository:
          repo: 'deb [signed-by=/etc/apt/keyrings/redis-archive-keyring.gpg] https://packages.redis.io/deb {{ ansible_distribution_release }} main'
          state: present
      - name: install Redis package
        package:
          name:
            - redis
          # force upgrade from stock Ubuntu version
          state: latest
      become: true
    - name: configure Redis to use at most {{ redis_maxmemory }} memory
      lineinfile:
        path: /etc/redis/redis.conf
        regex: ^(# *)?maxmemory\b
        line: maxmemory {{ redis_maxmemory }}
    - name: set Redis key eviction policy to {{ redis_maxmemory_policy }}
      lineinfile:
        path: /etc/redis/redis.conf
        regex: ^(# *)?maxmemory-policy\b
        line: maxmemory-policy {{ redis_maxmemory_policy }}
    - name: restart redis-server.service.
      ansible.builtin.systemd_service:
        state: restarted
        name: redis-server
      become: true

    - name: install Docker (required for GTFS Schedule import)
      ansible.builtin.apt:
        name: docker.io

    # These follow gtfs-rt-feed's readme: https://github.com/OpenDataVBB/gtfs-rt-feed/blob/b4bf9f6f482c541edacd237db960e051cd017fe5/readme.md#create-nats-stream--consumer.
    - name: ensure the NATS stream "{{ nats_ref_aus_sollfahrt_stream_name }}" is configured correctly
      ansible.builtin.shell: |
        nats stream add \
          --defaults \
          --subjects='{{ nats_ref_aus_sollfahrt_stream_subjects | join('\n') }}' \
          --description='{{ nats_ref_aus_sollfahrt_stream_description }}' \
          --ack --retention=limits --discard=old \
          --max-bytes='{{ nats_ref_aus_sollfahrt_stream_max_size_gb }}G' \
          '{{ nats_ref_aus_sollfahrt_stream_name }}'
    - name: ensure the NATS consumer "{{ nats_ref_aus_sollfahrt_consumer_name }}" for the "{{ nats_ref_aus_sollfahrt_stream_name }}" is configured correctly
      ansible.builtin.shell: |
        nats consumer add \
          --defaults \
          --pull --ack=explicit \
          --deliver='{{ nats_ref_aus_sollfahrt_consumer_deliver }}' \
          --max-pending='{{ nats_ref_aus_sollfahrt_consumer_max_pending }}' \
          --max-deliver='{{ nats_ref_aus_sollfahrt_consumer_max_deliver }}' \
          --backoff='{{ nats_ref_aus_sollfahrt_consumer_backoff }}' \
          --backoff-steps='{{ nats_ref_aus_sollfahrt_consumer_backoff_steps }}' \
          --backoff-min='{{ nats_ref_aus_sollfahrt_consumer_backoff_min }}' \
          --backoff-max='{{ nats_ref_aus_sollfahrt_consumer_backoff_max }}' \
          --description '{{ nats_ref_aus_sollfahrt_consumer_description }}' \
          '{{ nats_ref_aus_sollfahrt_stream_name }}' \
          '{{ nats_ref_aus_sollfahrt_consumer_name }}'
    - name: ensure the NATS stream "{{ nats_aus_istfahrt_stream_name }}" is configured correctly
      ansible.builtin.shell: |
        nats stream add \
          --defaults \
          --subjects='{{ nats_aus_istfahrt_stream_subjects | join('\n') }}' \
          --description='{{ nats_aus_istfahrt_stream_description }}' \
          --ack --retention=limits --discard=old \
          --max-bytes='{{ nats_aus_istfahrt_stream_max_size_gb }}G' \
          '{{ nats_aus_istfahrt_stream_name }}'
    - name: ensure the NATS consumer "{{ nats_aus_istfahrt_consumer_name }}" for the "{{ nats_aus_istfahrt_stream_name }}" is configured correctly
      ansible.builtin.shell: |
        nats consumer add \
          --defaults \
          --pull --ack=explicit \
          --deliver='{{ nats_aus_istfahrt_consumer_deliver }}' \
          --max-pending='{{ nats_aus_istfahrt_consumer_max_pending }}' \
          --max-deliver='{{ nats_aus_istfahrt_consumer_max_deliver }}' \
          --backoff='{{ nats_aus_istfahrt_consumer_backoff }}' \
          --backoff-steps='{{ nats_aus_istfahrt_consumer_backoff_steps }}' \
          --backoff-min='{{ nats_aus_istfahrt_consumer_backoff_min }}' \
          --backoff-max='{{ nats_aus_istfahrt_consumer_backoff_max }}' \
          --description '{{ nats_aus_istfahrt_consumer_description }}' \
          '{{ nats_aus_istfahrt_stream_name }}' \
          '{{ nats_aus_istfahrt_consumer_name }}'

    - name: clone OpenDataVBB/gtfs-rt-feed:{{ gtfs_rt_feed_git_ref }}
      ansible.builtin.git:
        repo: 'https://github.com/OpenDataVBB/gtfs-rt-feed.git'
        dest: '{{ gtfs_rt_feed_dir }}'
        version: '{{ gtfs_rt_feed_git_ref }}'
    - name: npm install
      community.general.npm:
        path: '{{ gtfs_rt_feed_dir }}'
    # GTFS import writes into `gtfs-rt-feed.service.d/pgdatabase.conf`.
    - name: create directory /etc/systemd/system/gtfs-rt-feed.service.d
      ansible.builtin.file:
        path: /etc/systemd/system/gtfs-rt-feed.service.d
        state: directory

    - name: put gtfs-rt-feed-* systemd unit files
      ansible.builtin.template:
        src: '../templates/{{ item }}.j2'
        dest: '/etc/systemd/system/{{ item }}'
      loop:
        - gtfs-rt-feed.service
        - gtfs-rt-feed-gtfs-import.service
        - gtfs-rt-feed-gtfs-import.timer
        - gtfs-rt-feed-pgdatabase-conf-watcher.path
        - gtfs-rt-feed-restarter.service
    - name: validate gtfs-rt-feed-* systemd unit files
      ansible.builtin.shell: |
        systemd-analyze verify /etc/systemd/system/{{ item }}
      loop:
        - gtfs-rt-feed.service
        - gtfs-rt-feed-gtfs-import.service
        - gtfs-rt-feed-gtfs-import.timer
        - gtfs-rt-feed-pgdatabase-conf-watcher.path
        - gtfs-rt-feed-restarter.service
    - name: enable gtfs-rt-feed-* systemd units
      ansible.builtin.systemd_service:
        daemon_reload: true
        enabled: true
        name: '{{ item }}'
      loop:
        - gtfs-rt-feed.service
        - gtfs-rt-feed-gtfs-import.service
        - gtfs-rt-feed-gtfs-import.timer
        - gtfs-rt-feed-pgdatabase-conf-watcher.path
        - gtfs-rt-feed-restarter.service

    - name: create "{{ gtfs_rt_feed_gtfs_importer_db }}" database
      # todo: use community.postgresql.postgresql_db instead?
      # https://docs.ansible.com/ansible/10/collections/community/postgresql/postgresql_db_module.html
      ansible.builtin.shell: |
        # https://stackoverflow.com/a/18389184/1072129
        # https://dba.stackexchange.com/a/337470/289704
        # note the trailing spaces before the `\`
        echo "\
        SELECT 'CREATE DATABASE \"{{ gtfs_rt_feed_gtfs_importer_db }}\"' \
        WHERE NOT EXISTS (\
          SELECT FROM pg_database WHERE datname = '{{ gtfs_rt_feed_gtfs_importer_db }}'\
        )\
        \gexec" | sudo -u postgres psql

    - name: run GTFS import manually
      ansible.builtin.shell: |
        systemctl restart --wait gtfs-rt-feed-gtfs-import.service

    - name: restart gtfs-rt-feed.service systemd unit
      ansible.builtin.systemd_service:
        state: restarted
        name: gtfs-rt-feed.service
