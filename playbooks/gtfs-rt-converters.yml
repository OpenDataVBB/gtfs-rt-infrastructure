---
- name: configure GTFS-RT converters/servers
  hosts: gtfs_rt_converter
  roles:
    - name: deploy NATS message queue
      become: true
      role: nats
      vars:
        nats_jetstream_enabled: true
        nats_jetstream_max_mem: 2G
        nats_jetstream_max_file: 10G

    - name: install Node.js from NodeSource's repo
      role: geerlingguy.nodejs
      vars:
        nodejs_version: '22.x'

    # todo: put StandardOutput=null in the [Service] section to disable logging?
    - name: install Caddy server
      role: caddy_ansible.caddy_ansible
      vars:
        caddy_packages:
          - 'github.com/mholt/caddy-ratelimit'
        caddy_systemd_capabilities_enabled: true
        caddy_config: "{{ lookup('template', '../templates/Caddyfile.j2') }}"

    - name: install PostgreSQL
      become: true
      role: geerlingguy.postgresql

    - name: install Prometheus
      role: prometheus.prometheus.prometheus
      vars:
        prometheus_web_listen_address: '{{ prometheus_listen_address }}' # only listen locally
        prometheus_storage_retention: '120d'
        prometheus_storage_retention_size: '20GB'
        prometheus_scrape_configs:
          - job_name: gtfs-rt-feed
            static_configs:
              - targets: ['localhost:{{ gtfs_rt_feed_metrics_server_port }}']
          - job_name: nats-consuming-gtfs-rt-server
            static_configs:
              - targets: ['localhost:{{ nats_consuming_gtfs_rt_server_metrics_server_port }}']
          - job_name: caddy
            static_configs:
              # https://caddyserver.com/docs/metrics
              - targets: ['localhost:2019']
          - job_name: prometheus-nats-exporter
            static_configs:
              - targets: ['localhost:7777']
          - job_name: prometheus-postgres-exporter
            static_configs:
              - targets: ['localhost:9187']
          - job_name: prometheus-redis-exporter
            static_configs:
              - targets: ['localhost:9121']
          - job_name: prometheus-node-exporter
            static_configs:
              - targets: ['localhost:9100']
          - job_name: prometheus-systemd-exporter
            static_configs:
              - targets: ['localhost:9558']
          - job_name: prometheus
            static_configs:
              - targets: ['{{ prometheus_listen_address }}']
    - name: install Prometheus PostgreSQL exporter
      role: prometheus.prometheus.postgres_exporter
      vars:
        postgres_exporter_name: 'postgresql://postgres:{{ postgresql_postgres_password }}@localhost/postgres?host=/var/run/postgresql'
        # Note: Some config values are modified via a systemd config override, see tasks below.
        postgres_exporter_disabled_collectors:
          - locks
          - replication
          - replication_slot
          - stat_bgwriter
          # The `stat_database` collector (enabled by default) exposes the database name as a label. Because postgis-gtfs-importer creates a new database on each import (gtfs_$timestamp_$hash), this creates a large number of time series.
          # > CAUTION: Remember that every unique combination of key-value label pairs represents a new time series, which can dramatically increase the amount of data stored. Do not use labels to store dimensions with high cardinality (many different label values), such as user IDs, email addresses, or other unbounded sets of values.
          # – https://prometheus.io/docs/practices/naming/
          # todo: investigate if this is a problem!
          # - stat_database
          - stat_user_tables
          - statio_user_tables
          - wal
        # default is `0.0.0.0:9187`
        postgres_exporter_web_listen_address: 'localhost:9187'
    - name: install Prometheus Redis exporter
      role: prometheus.prometheus.redis_exporter
      vars:
        # todo: adapt gtfs-rt-feed's keys naming, then use `redis_exporter_check_key_groups` to get insights into key usage
        # todo: adapt gtfs-rt-feed's keys naming to something more meaningful & self-explanatory!
        redis_exporter_count_keys:
          - '{{ gtfs_rt_feed_redis_db }}=*'
        redis_exporter_incl_system_metrics: true
        redis_exporter_redis_only_metrics: true
        # default is `0.0.0.0:9121`
        redis_exporter_web_listen_address: 'localhost:9121'

    # todo: move these to a general playbook
    - name: install Prometheus node exporter
      role: prometheus.prometheus.node_exporter
      vars:
        node_exporter_enabled_collectors:
          # > Collectors are enabled by providing a `--collector.<name>` flag. Collectors that are enabled by default can be disabled by providing a `--no-collector.<name>` flag. To enable only some specific collector(s), use `--collector.disable-defaults --collector.<name> ...`.
          # – https://github.com/prometheus/node_exporter/blob/v1.8.2/README.md#collectors
          - disable-defaults
          - cpu
          - diskstats
          - filesystem
          - hwmon
          - loadavg
          - meminfo
          - netdev
          - systemd
        # default is `0.0.0.0:9100`
        node_exporter_web_listen_address: 'localhost:9100'
    todo: remove in favor of Node Exporter's `systemd` collector – does this work?
    see https://github.com/prometheus/node_exporter/blob/v1.8.2/collector/systemd_linux.go#L158-L174
    - name: install Prometheus systemd exporter
      role: prometheus.prometheus.systemd_exporter
      vars:
        systemd_exporter_enable_restart_count: true
        # default is `0.0.0.0:9558`
        systemd_exporter_web_listen_address: 'localhost:9558'

    - name: install Grafana
      role: grafana.grafana.grafana
      vars:
        # todo: use the variable again – somehow this doesn't work :/
        # grafana_port: '{{ grafana_port }}'
        grafana_port: 8000
        grafana_address: '127.0.0.1' # `localhost` doesn't work
        grafana_url: '{{ grafana_public_endpoints[0] }}'
        grafana_security:
          admin_user: admin
          admin_password: '{{ grafana_admin_password }}'
        grafana_datasources:
          - uid: 'de29irtzi5gcga' # must match the `uid` in the dashboard files!
            name: 'prometheus localhost'
            type: prometheus
            access: proxy
            url: 'http://{{ prometheus_listen_address }}'
        grafana_dashboards_dir: ../lib/grafana/dashboards

  tasks:
    - name: set password of "postgres" user
      become: true
      ansible.builtin.shell: |
        sudo -u postgres psql -c "ALTER USER postgres PASSWORD '{{ postgresql_postgres_password }}'"
    - name: install PostGIS
      package:
        name:
          - postgis
    - name: create directory /etc/systemd/system/postgres_exporter.service.d
      ansible.builtin.file:
        path: /etc/systemd/system/postgres_exporter.service.d
        state: directory
      # become: true
    - name: "Prometheus PostgreSQL exporter: put systemd config override to prevent scraping pg_settings"
      ansible.builtin.copy:
        src: ../lib/prometheus/postgres-exporter-disable-pg-settings.conf
        dest: /etc/systemd/system/postgres_exporter.service.d/disable-pg-settings.conf
    - name: systemd daemon-reload & restart systemd gtfs-rt-feed.service
      ansible.builtin.systemd_service:
        daemon_reload: true
        state: restarted
        name: postgres_exporter

    - name: put grafana.Caddyfile
      ansible.builtin.template:
        src: '../templates/grafana.Caddyfile.j2'
        dest: /etc/caddy/grafana.Caddyfile
        owner: 'www-data'
    - name: reload Caddy config
      ansible.builtin.systemd_service:
        state: reloaded
        name: caddy

    - name: install Redis
      package:
        name:
          - redis
    - name: configure Redis to use at most {{ redis_maxmemory }} memory
      lineinfile:
        path: /etc/redis/redis.conf
        regex: ^(# *)?maxmemory\b
        line: maxmemory {{ redis_maxmemory }}
    - name: set Redis key eviction policy to {{ redis_maxmemory_policy }}
      lineinfile:
        path: /etc/redis/redis.conf
        regex: ^(# *)?maxmemory-policy\b
        line: maxmemory-policy {{ redis_maxmemory_policy }}

    - name: install Docker (required for GTFS Schedule import)
      ansible.builtin.apt:
        name: docker.io

    - name: clone OpenDataVBB/gtfs-rt-feed:{{ gtfs_rt_feed_git_ref }}
      ansible.builtin.git:
        repo: 'https://github.com/OpenDataVBB/gtfs-rt-feed.git'
        dest: '{{ gtfs_rt_feed_dir }}'
        version: '{{ gtfs_rt_feed_git_ref }}'
    - name: npm install
      community.general.npm:
        path: '{{ gtfs_rt_feed_dir }}'
    - name: put systemd gtfs-rt-feed.service unit file
      ansible.builtin.template:
        src: '../templates/gtfs-rt-feed.service.j2'
        dest: /etc/systemd/system/gtfs-rt-feed.service
    - name: validate gtfs-rt-feed.service
      ansible.builtin.shell: |
        systemd-analyze verify /etc/systemd/system/gtfs-rt-feed.service

    - name: create "{{ gtfs_rt_feed_gtfs_importer_db }}" database
      # todo: use community.postgresql.postgresql_db instead?
      # https://docs.ansible.com/ansible/10/collections/community/postgresql/postgresql_db_module.html
      ansible.builtin.shell: |
        # https://stackoverflow.com/a/18389184/1072129
        # https://dba.stackexchange.com/a/337470/289704
        # note the trailing spaces before the `\`
        echo "\
        SELECT 'CREATE DATABASE \"{{ gtfs_rt_feed_gtfs_importer_db }}\"' \
        WHERE NOT EXISTS (\
          SELECT FROM pg_database WHERE datname = '{{ gtfs_rt_feed_gtfs_importer_db }}'\
        )\
        \gexec" | sudo -u postgres psql
      become: true
    - name: run GTFS import manually
      ansible.builtin.shell: '{{ gtfs_rt_feed_import_cmd }}'

    # todo: use systemd unit, tie it to gtfs-rt-server.service? – or configure rsyslog to keep cron logs
    # see also https://www.splendid-internet.de/blog/besser-als-cronjobs-timer-units-mit-systemd/#Und_was_sind_Timer_Units

    - name: configure rsyslog to keep cron job logs
      ansible.builtin.copy:
        src: ../lib/rsyslog.d-enable-cron.conf
        dest: /etc/rsyslog.d/60-enable-cron.conf
    # Seems like we must restart rsyslog.service.
    # see https://serverfault.com/a/943575/1107343
    - name: restart rsyslog.service.
      ansible.builtin.systemd_service:
        state: restarted
        name: rsyslog

    - name: set up GTFS import cron job
      ansible.builtin.cron:
        name: 'gtfs-rt-feed: GTFS import'
        user: root # todo: use `www-data` instead?
        cron_file: gtfs-rt-feed-gtfs-import
        job: '{{ gtfs_rt_feed_import_cmd }}'
        # every hour
        minute: '3'

    - name: systemd daemon-reload, enable & restart systemd gtfs-rt-feed.service
      ansible.builtin.systemd_service:
        daemon_reload: true
        enabled: true
        state: restarted
        name: gtfs-rt-feed
    - name: reload Caddy config
      ansible.builtin.systemd_service:
        state: reloaded
        name: caddy

    - name: clone OpenDataVBB/nats-consuming-gtfs-rt-server:{{ nats_consuming_gtfs_rt_server_git_ref }}
      ansible.builtin.git:
        repo: 'https://github.com/OpenDataVBB/nats-consuming-gtfs-rt-server.git'
        dest: /srv/nats-consuming-gtfs-rt-server
        version: '{{ nats_consuming_gtfs_rt_server_git_ref }}'
    - name: npm install
      community.general.npm:
        path: /srv/nats-consuming-gtfs-rt-server
    - name: put systemd nats-consuming-gtfs-rt-server.service unit file
      ansible.builtin.template:
        src: '../templates/nats-consuming-gtfs-rt-server.service.j2'
        dest: /etc/systemd/system/nats-consuming-gtfs-rt-server.service
    - name: validate nats-consuming-gtfs-rt-server.service
      ansible.builtin.shell: |
        systemd-analyze verify /etc/systemd/system/nats-consuming-gtfs-rt-server.service
    - name: systemd daemon-reload, enable & start systemd nats-consuming-gtfs-rt-server.service
      ansible.builtin.systemd_service:
        daemon_reload: true
        enabled: true
        state: restarted
        name: nats-consuming-gtfs-rt-server

    # todo: delete old/superfluous remote files -> mirror
    - name: copy www files
      ansible.builtin.copy:
        src: '../files/www/{{ inventory_hostname }}/' # note the trailing slash
        dest: '{{ gtfs_rt_webroot }}'
    - name: put {{ gtfs_rt_webroot }}/index.html
      ansible.builtin.template:
        src: '../templates/www/index.html.j2'
        dest: '{{ gtfs_rt_webroot }}/index.html'

    - name: put gtfs-rt.Caddyfile
      ansible.builtin.template:
        src: '../templates/gtfs-rt.Caddyfile.j2'
        dest: /etc/caddy/gtfs-rt.Caddyfile
        owner: 'www-data'
    - name: validate Caddy config
      ansible.builtin.shell: |
        caddy validate -c /etc/caddy/Caddyfile
    - name: reload Caddy config
      ansible.builtin.systemd_service:
        state: reloaded
        name: caddy
