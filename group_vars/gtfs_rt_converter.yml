# NATS setup: streams, consumers
nats_ref_aus_sollfahrt_stream_name: REF_AUS_SOLLFAHRT_2
nats_ref_aus_sollfahrt_stream_description: 'VDV-453 REF-AUS SollFahrt messages'
nats_ref_aus_sollfahrt_stream_subjects:
  - 'ref_aus.sollfahrt.>'

nats_ref_aus_sollfahrt_consumer_name: gtfs-rt-feed
nats_ref_aus_sollfahrt_consumer_description: 'OpenDataVBB/gtfs-rt-feed'
nats_ref_aus_sollfahrt_consumer_deliver: new
nats_ref_aus_sollfahrt_consumer_max_pending: 100
nats_ref_aus_sollfahrt_consumer_max_deliver: 3
nats_ref_aus_sollfahrt_consumer_backoff: linear
nats_ref_aus_sollfahrt_consumer_backoff_steps: 2
nats_ref_aus_sollfahrt_consumer_backoff_min: 1m
nats_ref_aus_sollfahrt_consumer_backoff_max: 5m

nats_aus_istfahrt_stream_name: AUS_ISTFAHRT_2
nats_aus_istfahrt_stream_description: 'VDV-454 AUS IstFahrt messages'
nats_aus_istfahrt_stream_subjects:
  - 'aus.istfahrt.>'

nats_aus_istfahrt_consumer_name: gtfs-rt-feed
nats_aus_istfahrt_consumer_description: 'OpenDataVBB/gtfs-rt-feed'
nats_aus_istfahrt_consumer_deliver: new
nats_aus_istfahrt_consumer_max_pending: 100
nats_aus_istfahrt_consumer_max_deliver: 3
nats_aus_istfahrt_consumer_backoff: linear
nats_aus_istfahrt_consumer_backoff_steps: 2
nats_aus_istfahrt_consumer_backoff_min: 1m
nats_aus_istfahrt_consumer_backoff_max: 5m

# PostgreSQL
postgresql_major_version: 16 # todo: detect from target!
# password for user `postgres`
postgresql_postgres_password: !vault |
          $ANSIBLE_VAULT;1.1;AES256
          64326365376530323362623666636166336431373238623261613230363435663734643636653534
          3164636564653532663631353863393061616331373233380a373465363630656666613162633064
          32343262343935326531656535323233396333323330653535343365363132333964613337393436
          3438646362363964660a313361636561373237386238383663376163626630393863393233376137
          64333566323161613139306437366239373365323231616465333165663666353230
# number of parallel PostgreSQL queries, effectively
# - the concurrency of *uncached* matchings (defaults to `gtfs_rt_feed_db_pool_size`),
# - plus the concurrency of *uncached* station weight lookups (defaults to `gtfs_rt_feed_db_pool_size`),
# - plus some diagnostic connections (e.g. monitoring, manual debugging).
postgresql_max_connections: '{{ gtfs_rt_feed_db_pool_size * 2 + 3 | string }}'
postgresql_effective_cache_size: '23040MB'
postgresql_shared_buffers: '7680MB'
postgresql_maintenance_work_mem: '1920MB'

# Redis
redis_maxmemory: 4gb
# > Keeps most recently used keys; removes least recently used (LRU) keys
redis_maxmemory_policy: allkeys-lru
gtfs_rt_feed_redis_db: 1

# gtfs-rt-feed
gtfs_rt_feed_git_ref: main # todo: pin?
gtfs_rt_feed_dir: '/srv/gtfs-rt-feed'
# number of parallel PostgreSQL queries, effectively the concurrency of *uncached* matchings
gtfs_rt_feed_db_pool_size: '{{ ansible_processor_nproc * 1.2 | round | int }}' # todo: tweak?
# number of FeedEntities from NATS getting matched, effectively the concurrency of cached & uncached matchings together
gtfs_rt_feed_matching_concurrency: 50
# Schedule days are usually longer than 24 hours: they start a 00:00, but some trips run well beyond 23:59.
gtfs_rt_feed_matching_caching_ttl: 100800 # 1 day 4 hours, in seconds

# gtfs-rt-feed: GTFS import
gtfs_rt_feed_gtfs_importer_db: 'gtfs_importer'
gtfs_rt_feed_gtfs_download_user_agent: '{{ inventory_hostname }} GTFS import'

# monitoring
gtfs_rt_feed_metrics_server_port: 9091
prometheus_listen_address: 'localhost:9090' # only listen locally
prometheus_data_retention: 1y
prometheus_data_retention_size: 20GB
# We listen on the machine's Wireguard interface to make Grafana accessible to the other machines.
grafana_http_addr: '10.0.0.0'
